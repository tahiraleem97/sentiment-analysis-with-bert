{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cc84f9",
   "metadata": {},
   "source": [
    "# Installing and Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e105a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda\\envs\\env\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\anaconda\\envs\\env\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in c:\\anaconda\\envs\\env\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\envs\\env\\lib\\site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda\\envs\\env\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\envs\\env\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\envs\\env\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\env\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\envs\\env\\lib\\site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\envs\\env\\lib\\site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\envs\\env\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda\\envs\\env\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\envs\\env\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests->torchvision) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests->torchvision) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\envs\\env\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f42cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/c1/bd/f64d67df4d3b05a460f281defe830ffab6d7940b7ca98ec085e94e024781/transformers-4.34.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "     ---------------------------------------- 0.0/121.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/121.5 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/121.5 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/121.5 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/121.5 kB ? eta -:--:--\n",
      "     ------------ ------------------------ 41.0/121.5 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------------ ------------ 81.9/121.5 kB 353.1 kB/s eta 0:00:01\n",
      "     ------------------------ ------------ 81.9/121.5 kB 353.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 121.5/121.5 kB 374.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\anaconda\\envs\\env\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda\\envs\\env\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\envs\\env\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\envs\\env\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\envs\\env\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\env\\lib\\site-packages (from transformers) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/b3/34/65bb4b2d7908044963ebf614fe0fdb080773fc7030d7e39c8d3eddcd4257/PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\envs\\env\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/c3/29/0d9975fb739bdbefc73b6c23f335ea18e752fe6d2e91f3266a10dc8be140/tokenizers-0.14.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.14.1-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/da/33/f7437e23b0bb3f14014ab60de5948ca2b5187031e955e2db2fa872e35a3c/safetensors-0.4.0-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.0-cp311-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\envs\\env\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\envs\\env\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\envs\\env\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\envs\\env\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\envs\\env\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda\\envs\\env\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\anaconda\\envs\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\envs\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\envs\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/7.7 MB 3.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/7.7 MB 3.3 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.5/7.7 MB 3.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.6/7.7 MB 3.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.7/7.7 MB 3.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.9/7.7 MB 3.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.7 MB 3.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.2/7.7 MB 3.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.3/7.7 MB 3.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.5/7.7 MB 3.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/7.7 MB 3.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.7/7.7 MB 3.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/7.7 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.9/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.2/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.4/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.4/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.6/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.7/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.8/7.7 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.9/7.7 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.1/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.2/7.7 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.4/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.5/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.7/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.8/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.0/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.1/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.2/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.4/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.5/7.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.6/7.7 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.7/7.7 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.7/7.7 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.8/7.7 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.8/7.7 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.0/7.7 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.1/7.7 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.2/7.7 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.3/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.3/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.4/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.5/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.6/7.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.6/7.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.8/7.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.8/7.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.1/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.2/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.3/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.4/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.6/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.7/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.8/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.8/7.7 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.1/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.3/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.4/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.5/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.7/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.7/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.7/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.7/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.7/7.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 2.5 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Downloading safetensors-0.4.0-cp311-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.4 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 174.1/277.4 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  276.5/277.4 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 277.4/277.4 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.14.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.2 MB 8.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.2 MB 3.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.2 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.9/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.0/2.2 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.0 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 194.6/295.0 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 295.0/295.0 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.17.3 pyyaml-6.0.1 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers requests beautifulsoup4 pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af978c4",
   "metadata": {},
   "source": [
    "### Transformers is going to leverage us to download and use BERT NLP model\n",
    "### Requests will allow us to request Yelp site for scraping\n",
    "### Beautifulsoup4 will allow us scrap the data from the site and will be used to extract the data that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e51d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d2835",
   "metadata": {},
   "source": [
    "### autotokenizer will allow us to pass trough a string and convert that in to a sequence of numbers which we we can pass to our NLP model. Auto model for sequence classification is going to give us the architecture to form transformers to be able to load in to nlp model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56177a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84179367",
   "metadata": {},
   "source": [
    "# Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575e908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded038c",
   "metadata": {},
   "source": [
    "# Encode and Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1c09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode('Fine! It was ok', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e49f0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 12922,   106, 10197, 10140, 13563,   102]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af820dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] fine! it was ok [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we can also decode this token\n",
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b567e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39b087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.6455, -1.2697,  1.6994,  1.7555,  0.2988]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd34e9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6455, -1.2697,  1.6994,  1.7555,  0.2988]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d329ea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8bcfbb",
   "metadata": {},
   "source": [
    "# Review collection from YELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04b67fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.yelp.com/biz/tommaso-ristorante-italiano-san-francisco-2')\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "regex = re.compile('.*comment.*')\n",
    "results = soup.find_all('p', {'class':regex})\n",
    "reviews = [result.text for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81cff085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OMFG. FREAKING TO DIE FOR. If you like real Italian food, come. I got the lasagna and linguini with clams. Portions were perfect, not to the point you'd get food coma but still leave you more than satisfied. The educated guess glass of wine was $10 and very well worth. Well known for lasagna ($16.50). A taste of heaven, perfectly cheesy and the sauce isn't injected in the lasagna but poured on top, a delicious meat tomato sauce.The linguini, OMFG. I got the white sauce and it was seriously. So light, not the super creamy sauce that you get sick of halfway through. Definitely a hidden gem between hustler clubs and other strip clubs. It's a hole in the wall joint, very homey and small. Make reservations if you don't want to wait.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787aae05",
   "metadata": {},
   "source": [
    "# Loding reviews in to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6738d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb864b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(reviews), columns=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3c00e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ambiance is historic given location and Italian heritage of the place.Pizza brick oven is out of this world, we loved it.The rest, the pasta is well made and tasteful.  The chicken parmigiana was good as well as the eggplant dish.Price to portions ratio is adequate.Finally service was fast and effective.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5873981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cal(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17f57dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_cal(df['review'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1a464a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['review'].apply(lambda x: score_cal(x[:512]))\n",
    "# 512 represents the first 512 number of tokens to be passed in the model \n",
    "#Because the NLP pipeline can accomodate 512 tensors at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc05417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OMFG. FREAKING TO DIE FOR. If you like real It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMFG. FREAKING TO DIE FOR. If you like real It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ambiance is historic given location and Italia...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This place is definitely a legacy restaurant (...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank your for your review, Aubany. I do apolo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>There's so many things to love about North Bea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Daniel, thank you and your coworkers for payin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not quite four stars, but slightly closer to f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In a foodie city flush with 4 and 5 star resta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a beautifully written review, Frances. It...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Solid service.  Bustling restaurant.  Pizza an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In a neighborhood full of Italian this was pre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A busy NB restaurant ready to accommodate thei...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Absolutely shocked at how good this pasta is! ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  sentiment\n",
       "0   OMFG. FREAKING TO DIE FOR. If you like real It...          1\n",
       "1   OMFG. FREAKING TO DIE FOR. If you like real It...          1\n",
       "2   Ambiance is historic given location and Italia...          4\n",
       "3   This place is definitely a legacy restaurant (...          3\n",
       "4   Thank your for your review, Aubany. I do apolo...          4\n",
       "5   There's so many things to love about North Bea...          5\n",
       "6   Daniel, thank you and your coworkers for payin...          5\n",
       "7   Not quite four stars, but slightly closer to f...          3\n",
       "8   In a foodie city flush with 4 and 5 star resta...          4\n",
       "9   What a beautifully written review, Frances. It...          5\n",
       "10  Solid service.  Bustling restaurant.  Pizza an...          3\n",
       "11  In a neighborhood full of Italian this was pre...          2\n",
       "12  A busy NB restaurant ready to accommodate thei...          4\n",
       "13  Absolutely shocked at how good this pasta is! ...          5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac1427eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This place is definitely a legacy restaurant (not sure if it officially is but it should be)- a historical destination. ***Come for the nostalgia and the pizza. This time we didn't have any pizza and opted for the plates. Not the greatest decision on our part.The ambiance is the fun part as it's still the original paintings from the 1930s. Service seems like they are just there to do what they've always done and they don't like their jobs. It felt like diner service instead of quality restaurant service.The plating and quality of the food could definitely be upped. We had calamari, Veal Rollettini, and Chicken Parmesan. The sauce that was served with the calamari was the same sauce on the chicken parm and pasta. It needed help. The calamari was edible, but nothing exciting. The Veal Rollettini was the favorite, although the plate looked sad. Three rolls on a large plate sitting atop just grease. The chicken parm was edible, but I never want it again. I was super disappointed in this meal as the restaurant seems as though it would have the greatest food, since it's been around for so long. I've been impressed by the pizza in the past. The wine we had is a blend made only for Tommaso's and it was great. Worth a visit to say you've come, but don't come with expectations- and order pizza to be safe.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca9d8d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a neighborhood full of Italian this was pretty mediocre - not terrible. Service was meh/fine. We were starving so we ate and got outta there.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b4af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
